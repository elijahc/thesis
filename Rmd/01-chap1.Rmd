---
chapter: 1
knit: "bookdown::render_book"
---

# Introduction {#ch:intro}

Neurological and psychiatric disease represent a significant societal burden in both advanced and developing countries [@Collins:2011ja] and there is a significant need for more effective treatments.
Recent advances in brain stimulation and recording technology have enabled development of long-desired treatment options for many of these diseases in the form of implantable devices that directly stimulate populations of neurons.
Deep brain stimulation (DBS) is one such implantable device wherein patients receive electrical pulses via electrodes that have been implanted in the brain to mitigate their disease symptoms.
DBS has become an established therapy for movement disorders [@Perlmutter:2006kp] as well as epilepsy and psychiatric diseases [@Holtzheimer:2011eq].
Another group of implantable neurostimulators are neural prosthetics, such as cortical prostheses, which aim to restore sight in patients with congenital or acquired blindness. The body of work presented here makes progress on two unsolved challenges limiting advances in implantable neurostimulators, namely DBS state detection and more accurate cortical encoding of visual stimuli.

## Deep Brain Stimulation {#sec:dbs}

Deep brain stimulation (DBS) uses a surgically implanted stimulator to apply electrical pulses directly to the brain to mitigate symptoms of neurologic and psychiatric disease. Historically, drugs have been the primary method of treating these diseases, but DBS has emerged as a promising alternative for patients who don’t respond to pharmacotherapy. Parkinson’s disease (PD) was among the first FDA approved uses of DBS for mitigating the disease’s motor symptoms. When employed for treating PD, current best practice for DBS therapy uses constant stimulation even though its therapeutic benefits to motor symptoms are only needed when the patient is awake and trying to move (Fig \@ref(fig:dbs)). Current implanted stimulators are used this way because they have no way to detect when stimulation isn’t needed, such as when the patient is asleep or when lower levels of stimulation are needed to correct resting tremor. This strategy of constant stimulation, or open-loop stimulation, is less power efficient and comes with side effects such as impaired cognition, speech, gait, and balance [@Hariz:2008bf]. However, activating DBS stimulation only when necessary requires a robust method for discerning when the patient’s brain needs stimulation or not. For example, a closed-loop DBS system would read out the patient’s brain state and only deliver electrical pulses during periods when the patient is awake. Closed-loop DBS is more power efficient and would have less collateral side effects by only stimulating when necessary.

```{r dbs, echo=FALSE, message=FALSE, fig.align='center', out.width = '75%', fig.cap="Closed-loop DBS system would read out the patient’s brain state to modulate stimulation intensity accordingly based on if the patient is awake, stationary, or moving"}

knitr::include_graphics("img/dbs.png")

```

## Neural Interfaces {#sec:neuralinterfaces}

Cortical prosthetics (Fig 2) are a form of neural interface used to restore sight in blind patients(Lorach et al., 2013). These implantable neurostimulators bypass lost or damaged neurons and stimulating their targets as the original neurons otherwise would. Cortical prostheses must reproduce the neural activity patterns that would typically be relayed by naturally by neurons of the LGN and retina when directly stimulating visual cortex. Neural encoding, our understanding of how neurons reformat and represent visual stimuli, is key to this goal of properly restoring sight.

### Bottom-up neural encoding models

The ultimate test of our knowledge of neural encoding is to predict neural responses to stimuli. For instance, we know the visual cortex receives complex spatiotemporal patterns of light relayed by the retina and reformats these patterns to infer what caused them (i.e. the identity of the object).

A neuron’s receptive field (RF) depicts the properties of an image that modulate that neurons activity. RF’s are typically represented in model’s by linear filters applied at the first stage of processing.

These filters multiplied by an image and summed predict a given neurons response to that image. The linear RF model was insufficient for predicting several non-linear properties of retinal ganglion cell (RGC) responses to white noise.

Linear-Nonlinear-Poisson (LNP) (Paninski et al., 2004) models are commonly used to predict retinal ganglion cell (RGC) spike rates in responses to image stimuli.
LNP combines a linear spatial filter with a single static non-linearity.
The LNP model captured X variance for white noise stimuli but it doesn’t generalize to natural image stimuli.
Generalized Linear Model's (GLM) (Pillow et al., 2008) improve prediction accuracy by accounting for interactions between RGC’s and substituting the spatial receptive field with a spatiotemporal receptive field.

### Top-down neural encoding models {#sec:topdown}

The genome likely has insufficient capacity for specifying every neuronal connection (synapse) (Zador, 2019) so what mechanisms ensure that neurons are connected correctly?
This has recently been referred to as the “brain wiring problem” (Hassan and Hiesinger, 2015) and we’ll be looking specifically at how synaptic wiring is determined in visual cortex.
Before the eyes even open, molecular interactions and spontaneous activity of retinal ganglion cells (RGC’s) guide development of the initial “coarse” connectivity between retinal ganglion cells in the eye, neurons of the lateral geniculate nucleus in thalamus (LGN) and primary visual cortex (V1) (Del Rio and Feller, 2006; Katz and Shatz, 1996).
After this retinotopic map is established, synaptic connectivity continues refinement but requires environmental stimuli (Pietro Berkes et al., 2011). Identifying this “unifying principle” or computational goal (as Marr would say) that guides stimuli-dependent refinement of connectivity would help explain the structure of visual representations in V1 and beyond.

#### Sparse coding {#sec:sparsecoding}

Shortly after the discovery of simple and complex cells (Hubel and Wiesel, 1959), Horace Barlow proposed efficient coding (Barlow, 1961) as an explanation for the computations performed by neural circuits in sensory cortex. The efficient coding hypothesis posits that the overarching goal of sensory processing is to reduce the high information redundancy in stimuli from the physical environment. This view was strengthened by findings that the Gabor-like receptive fields of simple cells are an optimal basis set for natural scenes when optimizing for 1) representation sparsity and 2) image reconstruction (D. Field, 1987; Olshausen and D. J. Field, 1996) . Due to the highly metabolic nature of neurons, sparse coding was proposed as an alternative goal which has the added benefit of being metabolically and information efficient (Levy and Baxter, 1996). Sparse coding models were particularly influential after successfully predicting aspects of neural computations in retina (Atick and Redlich, 1992), thalamus (Dan et al., 1996) and primary visual cortex (V1) (Olshausen and D. J. Field, 1996).

Despite some modest successes at explaining the complex response properties of V2 (Lee et al., 2008; Olshausen et al., 2001) subsequent findings (Pietro Berkes et al., 2009; Willmore et al., 2011) have challenged the primacy of coding efficiency for explaining representations in higher visual areas. An informal definition of Shannon redundancy is the “wasted space” in a channel used in transmitting data. Most mammals have vastly more photoreceptors than fibers in the optic tract (Figure 1 left) where efficient coding could explain retinal coding as reducing redundancy to cross the compressed data channel of the optic fiber. In contrast, anatomical evidence indicate that redundancy probably increases as the channel goes from 106 retinal ganglion cells to the 109 neurons in primary visual cortex (Figure 1) (Barlow, 2001; Felleman and Van Essen, 1991).

#### Goal-directed convolutional neural networks {#sec:goaldirected}

Barlow, when reflecting later on his original idea (Barlow, 2001) makes a prescient statement, perhaps without knowing it: “We now need to step back and take a more global view of the brain’s task in order to see what lies behind the importance of recognizing redundancy”. Neural networks which optimize behaviorally relevant tasks(Yamins et al., 2014) have shown state of the art performance at predicting neuronal activity across the ventral visual stream.

## Summary {#sec:ch1summary}

Chapter [2](#ch:mlprimer) provides an introduction to machine learning that serves as a foundation for the technical chapters that follow.

In Chapter [3](#ch:jsr) we discuss work decoding sleep state using neural network models trained on direct intracranial recordings of human basal ganglia.
Importantly, this model generalizes decoding to patients never seen by the model and may allow new ways to leverage implantable stimulators for therapeutic benefit.

Chapter [4](#ch:vae) explores the effects multi-functional objectives (recognize and visualize) on both learned representations and task performance. This work was motivated by the observation that visual processing areas are reactivated during visualization tasks indicating their dual role in visual processing and regenerating stimuli. 

Finally, Chapter [5](#ch:jov) demonstrates the utility of neural network models as way to explain response properties of individual neurons. We achieved state of the art performance at predicting activity of individual neurons evoked by natural image stimuli in macaque V1 using a convolutional neural network. Furthermore, we used this model generatively to explain response properties of cells outside of Hubel and Wiesel’s simple- or complex-cell designations.


