<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>CH 1 Introduction | Computational Models of Neural Encoding in Vision and Neurostimulation</title>
  <meta name="description" content="CH 1 Introduction | Computational Models of Neural Encoding in Vision and Neurostimulation" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="CH 1 Introduction | Computational Models of Neural Encoding in Vision and Neurostimulation" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="CH 1 Introduction | Computational Models of Neural Encoding in Vision and Neurostimulation" />
  
  
  

<meta name="author" content="Elijah Christensen" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="preface.html"/>
<link rel="next" href="ch-mlprimer.html"/>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="templates/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">elijahc / thesis</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="ch-intro.html"><a href="ch-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ch-intro.html"><a href="ch-intro.html#sec:dbs"><i class="fa fa-check"></i><b>1.1</b> Deep Brain Stimulation</a></li>
<li class="chapter" data-level="1.2" data-path="ch-intro.html"><a href="ch-intro.html#sec:neuralinterfaces"><i class="fa fa-check"></i><b>1.2</b> Neural Interfaces</a></li>
<li class="chapter" data-level="1.3" data-path="ch-intro.html"><a href="ch-intro.html#sec:ch1summary"><i class="fa fa-check"></i><b>1.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-mlprimer.html"><a href="ch-mlprimer.html"><i class="fa fa-check"></i><b>2</b> Neuroscience and ML</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch-mlprimer.html"><a href="ch-mlprimer.html#sec:artificialunits"><i class="fa fa-check"></i><b>2.1</b> Artificial Units</a></li>
<li class="chapter" data-level="2.2" data-path="ch-mlprimer.html"><a href="ch-mlprimer.html#sec:layers"><i class="fa fa-check"></i><b>2.2</b> Layers</a></li>
<li class="chapter" data-level="2.3" data-path="ch-mlprimer.html"><a href="ch-mlprimer.html#sec:modarchetypes"><i class="fa fa-check"></i><b>2.3</b> Model Archetypes</a></li>
<li class="chapter" data-level="2.4" data-path="ch-mlprimer.html"><a href="ch-mlprimer.html#sec:architectures"><i class="fa fa-check"></i><b>2.4</b> Layer Architectures</a></li>
<li class="chapter" data-level="2.5" data-path="ch-mlprimer.html"><a href="ch-mlprimer.html#sec:lossfunc"><i class="fa fa-check"></i><b>2.5</b> Loss Function</a></li>
<li class="chapter" data-level="2.6" data-path="ch-mlprimer.html"><a href="ch-mlprimer.html#sec:learningrules"><i class="fa fa-check"></i><b>2.6</b> Learning Rules</a></li>
<li class="chapter" data-level="2.7" data-path="ch-mlprimer.html"><a href="ch-mlprimer.html#sec:optimizers"><i class="fa fa-check"></i><b>2.7</b> Optimizers</a></li>
<li class="chapter" data-level="2.8" data-path="ch-mlprimer.html"><a href="ch-mlprimer.html#sec:ch2summary"><i class="fa fa-check"></i><b>2.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch3-jsr.html"><a href="ch3-jsr.html"><i class="fa fa-check"></i><b>3</b> Predicting sleep state in human PD patients</a>
<ul>
<li class="chapter" data-level="" data-path="ch3-jsr.html"><a href="ch3-jsr.html#abstract"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="3.1" data-path="ch3-jsr.html"><a href="ch3-jsr.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="ch3-jsr.html"><a href="ch3-jsr.html#methods"><i class="fa fa-check"></i><b>3.2</b> Methods</a></li>
<li class="chapter" data-level="3.3" data-path="ch3-jsr.html"><a href="ch3-jsr.html#results"><i class="fa fa-check"></i><b>3.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-vae.html"><a href="ch-vae.html"><i class="fa fa-check"></i><b>4</b> Models of the ventral stream that visualize and categorize images</a>
<ul>
<li class="chapter" data-level="" data-path="ch-vae.html"><a href="ch-vae.html#abstract-1"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="4.1" data-path="ch-vae.html"><a href="ch-vae.html#materials-and-methods"><i class="fa fa-check"></i><b>4.1</b> Materials and Methods</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch5-jov.html"><a href="ch5-jov.html"><i class="fa fa-check"></i><b>5</b> Predicting single unit responses in macaque V1</a>
<ul>
<li class="chapter" data-level="" data-path="ch5-jov.html"><a href="ch5-jov.html#abstract-2"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="5.1" data-path="ch5-jov.html"><a href="ch5-jov.html#introduction-1"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="ch5-jov.html"><a href="ch5-jov.html#methods-1"><i class="fa fa-check"></i><b>5.2</b> Methods</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch5-discussion.html"><a href="ch5-discussion.html"><i class="fa fa-check"></i><b>6</b> (DRAFT) Single Units to Brain-wide States</a>
<ul>
<li class="chapter" data-level="" data-path="ch5-discussion.html"><a href="ch5-discussion.html#abstract-3"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="6.1" data-path="ch5-discussion.html"><a href="ch5-discussion.html#modeling-neural-encoding-with-anns"><i class="fa fa-check"></i><b>6.1</b> Modeling Neural Encoding with ANN’s</a></li>
<li class="chapter" data-level="6.2" data-path="ch5-discussion.html"><a href="ch5-discussion.html#deep-brain-stimulation"><i class="fa fa-check"></i><b>6.2</b> Deep Brain Stimulation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>REFERENCES</a></li>
<li class="divider"></li>
<li><strong><a href="https://github.com/rstudio/bookdown" target="blank">Proudly published with bookdown</a></strong></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Models of Neural Encoding in Vision and Neurostimulation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch:intro" class="section level1" number="1">
<h1><span class="header-section-number">CH 1</span> Introduction</h1>
<p>Neurological and psychiatric disease represent a significant societal burden in both advanced and developing countries <span class="citation">(Collins et al. <a href="references.html#ref-Collins:2011ja" role="doc-biblioref">2011</a>)</span> and there is a significant need for more effective treatments.
Recent advances in brain stimulation and recording technology have enabled development of long-desired treatment options for many of these diseases in the form of implantable devices that directly stimulate populations of neurons.
Deep brain stimulation (DBS) is one such implantable device wherein patients receive electrical pulses via electrodes that have been implanted in the brain to mitigate their disease symptoms.
DBS has become an established therapy for movement disorders (Parkinson’s Disease (PD) and essential tremor) <span class="citation">(Perlmutter and Mink <a href="references.html#ref-Perlmutter:2006kp" role="doc-biblioref">2006</a>)</span> as well as epilepsy and psychiatric diseases <span class="citation">(Holtzheimer and Mayberg <a href="references.html#ref-Holtzheimer:2011eq" role="doc-biblioref">2011</a>)</span>.
Another group of implantable neurostimulators are neural prosthetics, such as cortical prostheses, which aim to restore sight in patients with congenital or acquired blindness. The body of work presented here makes progress on two unsolved challenges limiting advances in implantable neurostimulators, namely DBS state detection and more accurate cortical encoding of visual stimuli.</p>
<div id="sec:dbs" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Deep Brain Stimulation</h2>
<p>Deep brain stimulation (DBS) uses a surgically implanted stimulator to apply electrical pulses directly to the brain to mitigate symptoms of neurologic and psychiatric disease. Historically, drugs have been the primary method of treating these diseases, but DBS has emerged as a promising alternative for patients who don’t respond to pharmacotherapy. Parkinson’s disease (PD) was among the first FDA approved uses of DBS for mitigating the disease’s motor symptoms. When employed for treating PD, current best practice for DBS therapy uses constant stimulation even though its therapeutic benefits to motor symptoms are only needed when the patient is awake and trying to move (Fig <a href="ch-intro.html#fig:dbs">1.1</a>). Current implanted stimulators are used this way because they have no way to detect when stimulation isn’t needed, such as when the patient is asleep or when lower levels of stimulation are needed to correct resting tremor. This strategy of constant stimulation, or open-loop stimulation, is less power efficient and comes with side effects such as impaired cognition, speech, gait, and balance <span class="citation">(Hariz et al. <a href="references.html#ref-Hariz:2008bf" role="doc-biblioref">2008</a>)</span>. However, activating DBS stimulation only when necessary requires a robust method for discerning when the patient’s brain needs stimulation or not. For example, a closed-loop DBS system would read out the patient’s brain state and only deliver electrical pulses during periods when the patient is awake. Closed-loop DBS is more power efficient and would have less collateral side effects by only stimulating when necessary.</p>
<div class="figure" style="text-align: center"><span id="fig:dbs"></span>
<img src="img/dbs.png" alt="Closed-loop DBS system would read out the patient’s brain state to modulate stimulation intensity accordingly based on if the patient is awake, stationary, or moving" width="75%" />
<p class="caption">
Figure 1.1: Closed-loop DBS system would read out the patient’s brain state to modulate stimulation intensity accordingly based on if the patient is awake, stationary, or moving
</p>
</div>
</div>
<div id="sec:neuralinterfaces" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Neural Interfaces</h2>
<p>Cortical prosthetics (Fig 2) are a form of neural interface used to restore sight in blind patients <span class="citation">(Lorach et al. <a href="references.html#ref-Lorach:2013ek" role="doc-biblioref">2013</a>)</span>. These implantable neurostimulators bypass lost or damaged neurons by stimulating the damaged neurons targets the same way the original neurons otherwise would. Cortical prostheses must reproduce the neural activity patterns that would typically be relayed by naturally by neurons of the LGN and retina when directly stimulating visual cortex. Neural encoding, our understanding of how neurons reformat and represent visual stimuli, is key to this goal of properly restoring sight.Unfortunately, current models of neural encoding still struggle to accurately predict neuron responses to natural images stimuli.</p>
<div id="bottom-up-neural-encoding-models" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Bottom-up neural encoding models</h3>
<p>The ultimate test of our knowledge of neural encoding is to predict neural responses to stimuli. For instance, we know the visual cortex receives complex spatiotemporal patterns of light relayed by the retina and reformats these patterns to infer what caused them (i.e. the identity of the object).</p>
<p>A neuron’s receptive field (RF) depicts the properties of an image that modulate that neurons activity. RF’s are typically represented in model’s by linear filters applied at the first stage of processing. The inner product (i.e. dot product) between the filter and corresponding image region predict a given neurons response to that image. The linear RF model was insufficient for predicting several non-linear properties of retinal ganglion cell (RGC) responses to white noise. Linear-Nonlinear-Poisson (LNP) (Paninski et al., 2004) models are commonly used to predict retinal ganglion cell (RGC) spike rates in responses to image stimuli.
LNP combines a linear spatial filter with a single static non-linearity.
The LNP model predicts neural responses well for white noise stimuli but it doesn’t generalize well used to predict responses to natural image stimuli. Generalized Linear Model’s (GLM) (Pillow et al., 2008) improve prediction accuracy by accounting for interactions between RGC’s and substituting the spatial receptive field with a spatiotemporal receptive field.</p>
</div>
<div id="sec:topdown" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Top-down neural encoding models</h3>
<p>The genome likely has insufficient capacity for specifying every neuronal connection (synapse) (Zador, 2019) so what mechanisms ensure that neurons are connected correctly?
This has recently been referred to as the “brain wiring problem” (Hassan and Hiesinger, 2015) and we’ll be looking specifically at how synaptic wiring is determined in visual cortex.
Before the eyes even open, molecular interactions and spontaneous activity of retinal ganglion cells (RGC’s) guide development of the initial “coarse” connectivity between retinal ganglion cells in the eye, neurons of the lateral geniculate nucleus in thalamus (LGN) and primary visual cortex (V1) (Del Rio and Feller, 2006; Katz and Shatz, 1996).
After this retinotopic map is established, synaptic connectivity continues refinement but requires environmental stimuli (Pietro Berkes et al., 2011). Identifying this “unifying principle” or computational goal that guides stimuli-dependent refinement of connectivity would help explain the structure of visual representations in V1 and beyond.</p>
<div id="sec:sparsecoding" class="section level4" number="1.2.2.1">
<h4><span class="header-section-number">1.2.2.1</span> Sparse coding</h4>
<p>Shortly after the discovery of simple and complex cells (Hubel and Wiesel, 1959), Horace Barlow proposed efficient coding (Barlow, 1961) as an explanation for the computations performed by neural circuits in sensory cortex. The efficient coding hypothesis posits that the overarching goal of sensory processing is to reduce the high information redundancy in stimuli from the physical environment. This view was strengthened by findings that the Gabor-like receptive fields of simple cells are an optimal basis set for natural scenes when optimizing for 1) representation sparsity and 2) image reconstruction (D. Field, 1987; Olshausen and D. J. Field, 1996) . Due to the highly metabolic nature of neurons, sparse coding was proposed as an alternative goal which has the added benefit of being metabolically and information efficient (Levy and Baxter, 1996). Sparse coding models were particularly influential after successfully predicting aspects of neural computations in retina (Atick and Redlich, 1992), thalamus (Dan et al., 1996) and primary visual cortex (V1) (Olshausen and D. J. Field, 1996).</p>
<p>Optimizing for efficient coding would predict information redundancy should decrease as it is processed and relayed by successive visual areas. Information redundancy decreases when the same information can be carried by fewer neurons, which occurs as visual information propagates from photoreceptors to retinal ganglion cells (RGC) and from retinal ganglion cells to the lateral geniculate nucleus (LGN) in the thalamus (Figure <a href="ch-intro.html#fig:channelcoding">1.2</a>). Instead of information redundancy decreasing, as would be predicted by efficient coding, anatomical evidence seems to indicates that information redundancy in primary visual cortex is likely higher than it is prior areas of visual processing <span class="citation">(Felleman and Van Essen <a href="references.html#ref-Felleman:1991tk" role="doc-biblioref">1991</a>, @Barlow:2001ub)</span>. Furthermore, despite some modest successes at explaining the complex response properties of V2 (the next visual area after V1) <span class="citation">(Lee, Ekanadham, and Ng <a href="references.html#ref-Lee:uz" role="doc-biblioref">2008</a>, @Olshausen:2001we)</span> subsequent findings <span class="citation">(Berkes, White, and Fiser <a href="references.html#ref-PietroBerkes:2009we" role="doc-biblioref">2009</a>, @Willmore:2011ks)</span> have shown that subsequent visual areas beyond V2 cannot be explained by the efficient coding hypothesis. Efficient coding alone as an objective is not sufficient for explaining response properties of neurons in higher level visual areas like V4 and inferior temporal cortex (IT).</p>
<div class="figure" style="text-align: center"><span id="fig:channelcoding"></span>
<img src="img/visual_channel_encoding.png" alt="Channel capacity, the number of neurons carrying visual information, significantly varies along the ventral visual stream" width="75%" />
<p class="caption">
Figure 1.2: Channel capacity, the number of neurons carrying visual information, significantly varies along the ventral visual stream
</p>
</div>
</div>
<div id="sec:goaldirected" class="section level4" number="1.2.2.2">
<h4><span class="header-section-number">1.2.2.2</span> Goal-directed convolutional neural networks</h4>
<p>Barlow, when reflecting later on his original idea (Barlow, 2001) makes a prescient statement, perhaps without knowing it: “We now need to step back and take a more global view of the brain’s task in order to see what lies behind the importance of recognizing redundancy”. Neural networks which optimize behaviorally relevant tasks(Yamins et al., 2014) have shown state of the art performance at predicting neuronal activity across the ventral visual stream.</p>
</div>
</div>
</div>
<div id="sec:ch1summary" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Summary</h2>
<p>Chapter <a href="ch-mlprimer.html#ch:mlprimer">2</a> provides an introduction to artificial neural networks, their similarities and differences to biological neurons, and the machine learning techniques used to train them which serves as a foundation for the technical chapters that follow.</p>
<p>In Chapter <a href="#ch:jsr">3</a> we demonstrate ANN models as tool for decoding sleep state in real-time using only the signals available from intracranial DBS electrodes implanted in the basal ganglia of PD patients.
Importantly, this model generalizes decoding to patients never seen by the model and may allow new ways to leverage implantable stimulators for therapeutic benefit.</p>
<p>Chapter <a href="ch-vae.html#ch:vae">4</a> explores how neural networks can be used as a tool for explaining the overarching goals of neural encoding in ventral stream visual processing. This work was motivated by the observation that visual processing areas are reactivated during visualization tasks indicating their dual role in visual processing and regenerating stimuli.</p>
<p>Finally, Chapter <a href="#ch:jov">5</a> demonstrates the utility of neural network models as way to explain response properties of individual neurons. We use a convolutional neural network (CNN) to achieve performance comparable to state of the art at predicting activity of individual neurons evoked by natural image stimuli in macaque V1. Furthermore, we used this model generatively to explain response properties of cells outside of Hubel and Wiesel’s simple- or complex-cell designations.</p>

</div>
</div>
<script type="application/json" class="js-hypothesis-config">

{"showHighlights": "whenSidebarOpen"}

</script>

<script src="https://hypothes.is/embed.js" async></script>
            </section>

          </div>
        </div>
      </div>
<a href="preface.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-mlprimer.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/elijahc/thesis/edit/master/Rmd//01-chap1.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["thesis.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
