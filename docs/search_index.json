[
["index.html", "Computational Models of Neural Encoding in Vision and Neurostimulation Welcome", " Computational Models of Neural Encoding in Vision and Neurostimulation Elijah Christensen Welcome This is the website for my PhD thesis at University of Colorado, titled “Computational Models of Neural Encoding in Vision and Neurostimulation”. 2020-04-16 "],
["acknowledgements.html", "Acknowledgements", " Acknowledgements Special thanks to Alon Poleg-Polsky for thoughtful discussion and direction and to Gidon Felsen for providing a place to call home. I would like to thank my support by the Department of Defense (DoD) through the National Defense Science &amp; Engineering Graduate Fellowship (NDSEG) Program as well as by the Canada First Research Excellence Fund (CFREF) and York University. "],
["preface.html", "Preface", " Preface The material in Chapter has been submitted to the journal Journal of Impossible Results for possible publication. The contribution in Chapter of this thesis was presented in the International Symposium on Nonsense held in Dublin, Ireland, in July 2015. "],
["ch-intro.html", "Chapter 1 INTRODUCTION 1.1 Deep Brain Stimulation 1.2 Neural Interfaces 1.3 Summary", " Chapter 1 INTRODUCTION Neurological and psychiatric disease represent a significant societal burden in both advanced and developing countries (Collins et al. 2011) and there is a significant need for more effective treatments. Recent advances in brain stimulation and recording technology have enabled development of long-desired treatment options for many of these diseases in the form of implantable devices that directly stimulate populations of neurons. Deep brain stimulation (DBS) is one such implantable device wherein patients receive electrical pulses via electrodes that have been implanted in the brain to mitigate their disease symptoms. DBS has become an established therapy for movement disorders (Perlmutter and Mink 2006) as well as epilepsy and psychiatric diseases (Holtzheimer and Mayberg 2011). Another group of implantable neurostimulators are neural prosthetics, such as cortical prostheses, which aim to restore sight in patients with congenital or acquired blindness. The body of work presented here makes progress on two unsolved challenges limiting advances in implantable neurostimulators, namely DBS state detection and more accurate cortical encoding of visual stimuli. 1.1 Deep Brain Stimulation Deep brain stimulation (DBS) uses a surgically implanted stimulator to apply electrical pulses directly to the brain to mitigate symptoms of neurologic and psychiatric disease. Historically, drugs have been the primary method of treating these diseases, but DBS has emerged as a promising alternative for patients who don’t respond to pharmacotherapy. Parkinson’s disease (PD) was among the first FDA approved uses of DBS for mitigating the disease’s motor symptoms. When employed for treating PD, current best practice for DBS therapy uses constant stimulation even though its therapeutic benefits to motor symptoms are only needed when the patient is awake and trying to move (Fig 1). Current implanted stimulators are used this way because they have no way to detect when stimulation isn’t needed, such as when the patient is asleep or when lower levels of stimulation are needed to correct resting tremor. This strategy of constant stimulation, or open-loop stimulation, is less power efficient and comes with side effects such as impaired cognition, speech, gait, and balance (Hariz et al., 2008). However, activating DBS stimulation only when necessary requires a robust method for discerning when the patient’s brain needs stimulation or not. For example, a closed-loop DBS system would read out the patient’s brain state and only deliver electrical pulses during periods when the patient is awake. Closed-loop DBS is more power efficient and would have less collateral side effects by only stimulating when necessary. 1.2 Neural Interfaces Cortical prosthetics (Fig 2) are a form of neural interface used to restore sight in blind patients(Lorach et al., 2013). These implantable neurostimulators bypass lost or damaged neurons and stimulating their targets as the original neurons otherwise would. Cortical prostheses must reproduce the neural activity patterns that would typically be relayed by naturally by neurons of the LGN and retina when directly stimulating visual cortex. Neural encoding, our understanding of how neurons reformat and represent visual stimuli, is key to this goal of properly restoring sight. 1.2.1 Bottom-up neural encoding models The ultimate test of our knowledge of neural encoding is to predict neural responses to stimuli. For instance, we know the visual cortex receives complex spatiotemporal patterns of light relayed by the retina and reformats these patterns to infer what caused them (i.e. the identity of the object). A neuron’s receptive field (RF) depicts the properties of an image that modulate that neurons activity. RF’s are typically represented in model’s by linear filters applied at the first stage of processing. These filters multiplied by an image and summed predict a given neurons response to that image. The linear RF model was insufficient for predicting several non-linear properties of retinal ganglion cell (RGC) responses to white noise. Linear-Nonlinear-Poisson (LNP) (Paninski et al., 2004) models are commonly used to predict retinal ganglion cell (RGC) spike rates in responses to image stimuli. LNP combines a linear spatial filter with a single static non-linearity. The LNP model captured X variance for white noise stimuli but it doesn’t generalize to natural image stimuli. Generalized Linear Model’s (GLM) (Pillow et al., 2008) improve prediction accuracy by accounting for interactions between RGC’s and substituting the spatial receptive field with a spatiotemporal receptive field. 1.3 Summary Chapter 2 provides an introduction to machine learning that serves as a foundation for the technical chapters that follow. In Chapter 3 we discuss our work decoding sleep state using neural network models trained on direct intracranial recordings of human basal ganglia. Importantly, this model generalizes decoding to patients never seen by the model and may allow new ways to leverage implantable stimulators for therapeutic benefit. Chapter 4 explores the effects multi-functional objectives (recognize and visualize) on both learned representations and task performance. This work was motivated by the observation that visual processing areas are reactivated during visualization tasks indicating their dual role in visual processing and regenerating stimuli. Finally, Chapter 5 demonstrates the utility of neural network models as way to explain response properties of individual neurons. We achieved state of the art performance at predicting activity of individual neurons evoked by natural image stimuli in macaque V1 using a convolutional neural network. Furthermore, we used this model generatively to explain response properties of cells outside of Hubel and Wiesel’s simple- or complex-cell designations. REFERENCES "],
["ch-mlprimer.html", "Chapter 2 MACHINE LEARNING AND COMPUTATIONAL NEUROSCIENCE 2.1 Artificial Units 2.2 Layers 2.3 Model Archetypes 2.4 Layer Architectures 2.5 Loss Function 2.6 Learning Rules 2.7 Optimizers", " Chapter 2 MACHINE LEARNING AND COMPUTATIONAL NEUROSCIENCE Despite the importance of computers for conducting machine learning and computational neuroscience research both fields had origins long before contemporary transistor computers. In 1943, inspired by the “all-or-none” nature of neural activity, Warren McCulloch (neuroscientist) and Walter Pitts (logician) formalized a simple mathematical definition of a neuron (McCulloch and Pitts 1943). McCulloch and Pitts neurons became the fundamental unit of artificial neural networks (ANN). These artificial neurons, often referred to as (artificial) units, reproduce several key properties of real neurons (Figure 2.1A ). Biological neurons receive input from many other neurons via connections (e.g. synapses) to its dendrites. These synaptic inputs are summated at the soma where the net dendritic input increases or decreases the neurons membrane potential (Fig 2.1A). If the net dendritic input shifts the membrane potential beyond a certain threshold (e.g. the threshold potential) the neuron will fire action potentials. 2.1 Artificial Units Artificial units (Fig 2.1B) are the basic building block of artificial neural networks. Each artificial unit receives input represented as a sequence of inputs \\(x_i\\) and each input has a corresponding synaptic weight \\(w_i\\). The membrane potential \\(z\\) of the artificial unit is represented by adding net dendritic input to a scalar bias term \\(b\\) which represents intrinsic excitability. Finally, the threshold non-linear response of biological neurons is captured by passing the units membrane potential \\(z\\) through an activation function \\(g\\) which gives the unit output firing rate, or “activation”, \\(a\\). \\[ a_j = g(z_j) = g(x_i \\cdot w_{i,j} + b_j) \\] 2.2 Layers Just as the brain is comprised of more than one neuron, most models make use of many artificial units. Similar to the laminar organization of the neocortex, artificial neural networks (ANN) group individual units together in layers (Fig 2.1C). The artificial units within a layer collectively operate on a shared input and the layers output consists the collective activations of its constituent artificial units. ANN layers in a model between the inputs (x) and final outputs (y) are often referred to as “hidden” layers. The layers of an ANN are often considered analogous to a population of neurons in regions of the brain which perform similar functions. For instance, primary visual cortex (V1) contain a population of neurons which receive visual inputs from the retina (relayed by LGN). As a population of neurons, V1 processes this visual input and this processed visual information is then relayed to area V2 for subsequent processing. Figure 2.1: Real neurons and artificial units 2.3 Model Archetypes Deep artificial neural network models typically have multiples of these layers stacked one after the other, such that the outputs of one layer become the inputs for the subsequent layer. Deep ANN models are often constructed for a specific purpose, or to perform a specific task. Models are often categorized based on purported task and the structure of the inputs it uses to accomplish this task. For instance, many computer vision researchers train models which, given an image, categorize the object in the image. 2.3.1 Classifiers Classifiers are a class of models that attempt to predict the best category that describes the input from a discrete number of categories. For example, a classic machine learning exercise has been to train a model to predict the category of an object depicted in an image. MNIST, Fashion-MNIST (Xiao, Rasul, and Vollgraf 2017), CIFAR10/100 (Krizhevsky and Hinton 2009) and ImageNet are examples of large labeled image datasets that have been historically popular for evaluating a model’s classification performance. Classifiers are not specific image tasks and can be used on any discrete labeling task. For instance, in Chapter 3 we trained an ANN classifier to predict behavioral sleep state in human PD patients based on features from local field potential spectral decompositions. 2.3.2 Regressors Regressors use their inputs and attempt to predict a continuous value purportedly derived from the input. Recently, neural network models have been used as functional models of the visual system. These models use images to predict neuronal firing rates observed in animals after viewing the same image and has been used to successfully for predicting stimulus evoked activity in retina (McIntosh et al. 2016) and Inferior Temporal cortex (IT) (Yamins et al. 2014). We successfully utilized a convolutional neural network regressor model to predict firing responses for populations of neurons in macaque primary visual cortex (V1) which is the subject of Chapter 5. 2.3.3 Autoencoders Autoencoders are a special class of models which attempt to predict their inputs. This is a trivial task if each the intermediate hidden layers have similar dimensionality as the input and output; the model can simply learn to copy the input into the output. Instead, these models are more often configured to have far few dimensions in their hidden layers. In this configuration the only way to successfully perform the task is to exploit information redundancy in the input to compress the input while retaining as much information as possible. 2.4 Layer Architectures Training an ANN model using machine learning typically requires three components. These components are 1) the model’s layer architecture, 2) objective or loss function, and 3) the models learning rules. The layer architecture of a model explicitly specifies how the artificial units, organized in layers, are connected from input to output. There are a wide variety of layers to choose from when constructing a deep ANN but for the sake of brevity only descriptions of layer architectures used in this work will be provided. 2.4.1 All-to-all All-to-all layers are the simplest and oldest of layer architectures. In all-to-all layers, every input is connected to every unit in the layer. We can describe this ANN layer mathematically by vectorizing the previous equation wherein inputs and output firing rates are represented as vectors \\((x_i,a_j)\\) instead of scalars \\((x,a)\\): 2.5 Loss Function Loss or cost functions ( \\(J\\) ) are mathematical definitions of the goal of the learning system. The loss function is used to calculate a scalar metric quantifying the models’ task performance as a function of its output. Loss functions can take any form mathematically as long as they are 1) differentiable and 2) convex. Reconstruction error (sum of squared pixel errors) were traditionally used for training models which attempt to generate a particular image. We can express the sum squared pixel loss between an image \\(\\hat{y}\\) and the target reference \\(y\\) as: \\[ J(y,\\hat{y}) = \\sum (y-\\hat{y})^2 \\] Objective functions don’t have to depend on a particular dataset or task. For instance, sparse coding models use activation sparseness and reconstruction error as their objective function to learn sparse representations. When minimized over images of natural scenes they learn a set of basis functions that resemble localized receptive fields of simple cells in primary visual cortex (Olshausen and Field 1996) 2.6 Learning Rules Once a model’s architecture and objective function are specified “training” it is simply optimizing the parameters of each layer to improve its loss. The algorithm for how to iteratively update the ANN model parameters to minimize loss was first demonstrated by Rumelhart (Rumelhart, Hinton, and Williams 1986) and it is a simple 2 step process: Forward pass: Use a batch of \\(x\\) input values to calculate the predicted outputs \\(\\hat{y}\\) Backpropogation: Use prediction error to update weights and biases To illustrate this process, we will derive it for a simple 2-layer ANN. For simplicity, we change notation when describing deep ANN with multiple layers such that variable and function subscripts denote the variable or function’s corresponding layer NOT matrix or vector dimensions. For instance, we define the output activations of the lth layer in a model comprised of sequentially stacked all-to-all layers as: \\[ a_l = g(a_{l-1} \\cdot W_l + b_l) \\] 2.6.1 Forward Pass First, we pass a batch of training example inputs (\\(x\\)) through the model to get a batch of output classifications (\\(\\hat{y}\\)). Given our simple feedforward layer defined above, the full equation for the models output is given by: \\[ \\hat{y} = g(W_2 \\cdot g(W_1 \\cdot x +b_1) + b_2) \\] Our loss function \\(J\\) defines how to evaluate the model’s performance as a function of the model’s predicted and target values. The target value is also sometimes referred to as the teaching signal, as it’s used to teach the model the correct output for a given input. For this example, we’ll use sum-squared-error: \\[ J(y,\\hat{y}) = \\sum (y-\\hat{y})^2 \\] 2.6.2 Backpropagation To derive the gradient of the loss function with respect to the model parameters (\\(\\nabla_{\\theta} J\\)) we take a partial derivative of the objective function with respect to the models parameters: \\[ \\nabla_{\\theta} J = \\frac{\\partial J(\\theta ; y, \\hat{y})}{\\partial \\theta} \\] 2.7 Optimizers Once we know the gradient of each weight with respect to the loss, we simply need to adjust the weights of the model in the direction specified by the weight gradient. Continually descending the gradient of the loss function should theoretically result in the optimal weights for performing the model’s task. REFERENCES "],
["references.html", "REFERENCES", " REFERENCES Collins, Pamela Y, Vikram Patel, Sarah S Joestl, Dana March, Thomas R Insel, Abdallah S Daar, Scientific Advisory Board and the Executive Committee of the Grand Challenges on Global Mental Health, et al. 2011. “Grand challenges in global mental health.” Nature 475 (7354): 27–30. Holtzheimer, Paul E, and Helen S Mayberg. 2011. “Deep brain stimulation for psychiatric disorders.” Annual Review of Neuroscience 34 (1): 289–307. Krizhevsky, A, and G Hinton. 2009. “Learning multiple layers of features from tiny images.” McCulloch, W S, and W Pitts. 1943. A logical calculus of the ideas immanent in nervous activity. Vol. 52. McIntosh, Lane T, Niru Maheswaranathan, Aran Nayebi, Surya Ganguli, and Stephen A Baccus. 2016. “Deep Learning Models of the Retinal Response to Natural Scenes.” Advances in Neural Information Processing Systems 29: 1369–77. Olshausen, B A, and D J Field. 1996. “Emergence of simple-cell receptive field properties by learning a sparse code for natural images.” Nature 381 (6583): 607–9. Perlmutter, Joel S, and Jonathan W Mink. 2006. “Deep brain stimulation.” Annual Review of Neuroscience 29: 229–57. Rumelhart, David E, Geoffrey E Hinton, and Ronald J Williams. 1986. “Learning representations by back-propagating errors.” Nature 323 (6088): 533–36. Xiao, Han, Kashif Rasul, and Roland Vollgraf. 2017. “Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms,” August. http://arxiv.org/abs/1708.07747. Yamins, Daniel L K, Ha Hong, Charles F Cadieu, Ethan A Solomon, Darren Seibert, and James J DiCarlo. 2014. “Performance-optimized hierarchical models predict neural responses in higher visual cortex.” Proceedings of the National Academy of Sciences of the United States of America 111 (23): 8619–24. "]
]
